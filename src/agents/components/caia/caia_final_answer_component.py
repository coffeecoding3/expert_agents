"""
CAIA Final Answer Component
ìµœì¢… ë‹µë³€ ìƒì„± ì»´í¬ë„ŒíŠ¸ - ê²€ìƒ‰ ê²°ê³¼ì™€ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
"""

from logging import getLogger
from typing import Any, Dict

from langchain_core.messages import AIMessage

from src.agents.components.common.llm_component import LLMComponent
from src.llm.interfaces.chat import ChatMessage, MessageRole
from src.orchestration.states.caia_state import CAIAAgentState
from src.schemas.sse_response import SSEResponse
from src.utils.log_collector import collector
from src.utils.tool_name_mapper import ToolNameMapper

logger = getLogger("agents.caia_final_answer_component")


class CAIAFinalAnswerComponent(LLMComponent):
    """CAIA ìµœì¢… ë‹µë³€ ìƒì„± ì»´í¬ë„ŒíŠ¸"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        super().__init__(agent_code="caia")

    def _build_final_prompt(self, state: CAIAAgentState) -> str:
        """ìµœì¢… ë‹µë³€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        from src.prompts.prompt_manager import prompt_manager

        # ê²€ìƒ‰ ê²°ê³¼ëŠ” ì§ì ‘ stateì— ë³‘í•©ë˜ì–´ ìˆìŒ
        summary = state.get("summary", "")
        tool_results = state.get("tool_results", [])
        unified_tool_results = state.get("unified_tool_results", [])

        logger.debug(f"[FINAL_ANSWER] Summary length: {len(summary)}")
        logger.debug(f"[FINAL_ANSWER] Tool results count: {len(tool_results)}")
        logger.debug(
            f"[FINAL_ANSWER] Unified tool results count: {len(unified_tool_results)}"
        )

        # ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ
        query = state.get("user_query")
        user_context = state.get("user_context", {})

        # ëŒ€í™” ì´ë ¥ í¬ë§·íŒ…
        chat_history = user_context.get("recent_messages", [])
        chat_history = str(chat_history)

        # ì‚¬ìš©ì ë©”ëª¨ë¦¬ ì •ë³´
        long_term_memories = user_context.get("long_term_memories", "")
        user_info = long_term_memories

        # ì‚¬ìš©ì ê°œì¸ ë©”ëª¨ë¦¬ ì •ë³´
        personal_memories = user_context.get("personal_info", "")
        personal_info = personal_memories.get("personal_memories", "")

        # ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
        documents_parts = []

        if summary:
            documents_parts.append(f"## ê²€ìƒ‰ ìš”ì•½:\n{summary}")
            logger.debug(f"[FINAL_ANSWER_DEBUG] Added summary to documents")

        # unified_tool_resultsê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ tool_results ì‚¬ìš©
        results_to_use = unified_tool_results if unified_tool_results else tool_results

        if results_to_use and isinstance(results_to_use, list):
            documents_parts.append("## ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼:")
            sources_info = []  # ì¶œì²˜ ì •ë³´ ìˆ˜ì§‘

            for i, result in enumerate(results_to_use, 1):
                logger.debug(
                    f"[FINAL_ANSWER_DEBUG] Tool result {i}: {type(result)} - {str(result)[:200]}..."
                )
                if isinstance(result, dict):
                    tool_name = result.get("tool", "unknown")
                    korean_tool_name = ToolNameMapper.get_korean_name(tool_name)
                    formatted_result = result.get("formatted_result", "")
                    raw_result = result.get("raw_result", {})

                    if formatted_result:
                        # ì¶œì²˜ ì •ë³´ ì¶”ì¶œ
                        source_info = self._extract_source_info(
                            tool_name, raw_result, korean_tool_name
                        )
                        if source_info:
                            sources_info.append(source_info)

                        documents_parts.append(
                            f"### {i}. {korean_tool_name} ê²°ê³¼:\n{formatted_result}"
                        )
                        logger.debug(
                            f"[FINAL_ANSWER_DEBUG] Added tool {i} formatted_result to documents"
                        )

            # ì¶œì²˜ ì •ë³´ê°€ ìˆìœ¼ë©´ ë³„ë„ ì„¹ì…˜ìœ¼ë¡œ ì¶”ê°€
            if sources_info:
                documents_parts.append("## ğŸ“š ì¶œì²˜ ì •ë³´:")
                documents_parts.extend(sources_info)
                logger.debug(
                    f"[FINAL_ANSWER_DEBUG] Added {len(sources_info)} sources to documents"
                )

        documents = (
            "\n\n".join(documents_parts) if documents_parts else "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        )

        # í˜„ì¬ ë‚ ì§œ ì •ë³´ ì¶”ê°€
        from src.utils.timezone_utils import get_current_time_in_timezone

        current_time = get_current_time_in_timezone()
        current_date = current_time.strftime("%Y-%m-%d")

        logger.info("[FINAL_ANSWER] ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤")
        context: Dict[str, Any] = {
            "user_query": query,
            "chat_history": chat_history,
            "user_info": user_info,
            "personal_info": personal_info,
            "documents": documents,
            "current_date": current_date,
        }

        return prompt_manager.render_template(
            "caia/caia_final_answer_v2.j2",
            context,
        )

    def _extract_source_info(
        self, tool_name: str, raw_result: dict, korean_tool_name: str
    ) -> str:
        """ë„êµ¬ë³„ë¡œ ì¶œì²˜ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤"""
        if not isinstance(raw_result, dict):
            return ""

        source_entries = []

        if tool_name == "retrieve_coporate_knowledge":
            # ì‚¬ë‚´ì§€ì‹ ë„êµ¬ì˜ ê²½ìš° ë¬¸ì„œ ì¶œì²˜ ì •ë³´ (ì œëª©, íŒŒì¼ëª…, ë§í¬ê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ)
            if "documents" in raw_result:
                documents = raw_result.get("documents", [])
                for doc in documents:
                    if isinstance(doc, dict):
                        filename = doc.get("filename", "")
                        view_url = doc.get("view_url", "")
                        title = doc.get("title", doc.get("custom_title", ""))

                        # ì œëª©, íŒŒì¼ëª…, ë§í¬ê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ ì¶œì²˜ë¡œ ì¶”ê°€
                        if title and filename and view_url:
                            source_entry = (
                                f"- ğŸ“„ **{title}** (íŒŒì¼: {filename}, ë§í¬: {view_url})"
                            )
                            source_entries.append(source_entry)

        elif tool_name == "get_events":
            # ì¼ì • ë„êµ¬ì˜ ê²½ìš° ì´ë²¤íŠ¸ ì¶œì²˜ ì •ë³´ (ì œëª©, ì‹œê°„, ì¥ì†Œê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ)
            if "events" in raw_result:
                events = raw_result.get("events", [])
                for event in events:
                    if isinstance(event, dict):
                        subject = event.get("subject", "")
                        start_time = event.get("start", {}).get("dateTime", "")
                        location = event.get("location", {}).get("displayName", "")

                        # ì œëª©, ì‹œê°„, ì¥ì†Œê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ ì¶œì²˜ë¡œ ì¶”ê°€
                        if subject and start_time and location:
                            source_entry = (
                                f"- ğŸ“… **{subject}** ({start_time}) - {location}"
                            )
                            source_entries.append(source_entry)

        elif tool_name == "get_mails":
            # ë©”ì¼ ë„êµ¬ì˜ ê²½ìš° ë©”ì¼ ì¶œì²˜ ì •ë³´ (ì œëª©, ë°œì‹ ì, ìˆ˜ì‹ ì‹œê°„ì´ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ)
            if "messages" in raw_result:
                messages = raw_result.get("messages", [])
                for message in messages:
                    if isinstance(message, dict):
                        subject = message.get("subject", "")
                        sender = (
                            message.get("from", {})
                            .get("emailAddress", {})
                            .get("name", "")
                        )
                        received_time = message.get("receivedDateTime", "")

                        # ì œëª©, ë°œì‹ ì, ìˆ˜ì‹ ì‹œê°„ì´ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ ì¶œì²˜ë¡œ ì¶”ê°€
                        if subject and sender and received_time:
                            source_entry = f"- ğŸ“§ **{subject}** (ë°œì‹ ì: {sender}, {received_time})"
                            source_entries.append(source_entry)

        elif tool_name in ["web_search", "get_web_search_data"]:
            # ì›¹ê²€ìƒ‰ ë„êµ¬ì˜ ê²½ìš° ì›¹ ì¶œì²˜ ì •ë³´
            if "results" in raw_result:
                results = raw_result.get("results", [])
                for result in results:
                    if isinstance(result, dict):
                        title = result.get("title", "")
                        url = result.get("url", "")

                        # ì œëª©ê³¼ URLì´ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ ì¶œì²˜ë¡œ ì¶”ê°€
                        if title and url:
                            source_entry = f"- ğŸŒ **{title}** ({url})"
                            source_entries.append(source_entry)

        # ì¶œì²˜ ì •ë³´ê°€ ìˆìœ¼ë©´ ë„êµ¬ëª…ê³¼ í•¨ê»˜ ë°˜í™˜
        if source_entries:
            return f"### {korean_tool_name} ì¶œì²˜:\n" + "\n".join(source_entries)

        return ""

    async def generate_final_answer(self, state: CAIAAgentState) -> Dict[str, Any]:
        """ìµœì¢… ë‹µë³€ ìƒì„±"""
        try:
            # ë””ë²„ê¹…: ë°›ì€ state êµ¬ì¡° í™•ì¸
            logger.debug(
                f"[FINAL_ANSWER_DEBUG] Received state keys: {list(state.keys())}"
            )
            logger.debug(
                f"[FINAL_ANSWER_DEBUG] Received state summary: {state.get('summary', 'NOT_FOUND')}"
            )
            logger.debug(
                f"[FINAL_ANSWER_DEBUG] Received state tool_results: {state.get('tool_results', 'NOT_FOUND')}"
            )
            logger.debug(
                f"[FINAL_ANSWER_DEBUG] Received state unified_tool_results: {state.get('unified_tool_results', 'NOT_FOUND')}"
            )

            final_prompt = self._build_final_prompt(state)
            logger.debug(f"[DEBUG] final_prompt: {final_prompt}")

            if final_prompt is None:
                logger.warning("[DEBUG] final_prompt is None")
                return {"error": "í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨"}

            # ì‹¤ì œ input/output ë¡œê·¸ ì¶œë ¥
            logger.debug(f"[FINAL_ANSWER_INPUT] Prompt: {final_prompt}...")
            collector.log("final_prompt", final_prompt)

            # LLMComponentì˜ chat ë©”ì„œë“œ ì‚¬ìš©
            response = await self.chat(
                messages=[ChatMessage(role=MessageRole.USER, content=final_prompt)]
            )

            # ì‹¤ì œ output ë¡œê·¸ ì¶œë ¥
            logger.debug(f"[FINAL_ANSWER_OUTPUT] Response: {response.content}...")
            collector.log("final_answer", response.content)

            content = getattr(response, "content", str(response))
            return {"messages": [AIMessage(content=content)], "success": True}

        except Exception as e:
            logger.error(f"[GRAPH][7/7] ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "messages": [
                    AIMessage(content="ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                ],
                "success": False,
                "error": str(e),
            }

    async def stream_final_answer(self, state: CAIAAgentState):
        """ìŠ¤íŠ¸ë¦¬ë° ìµœì¢… ë‹µë³€ ìƒì„±"""
        try:
            final_prompt = self._build_final_prompt(state)
            accumulated_content = ""
            async for response in self.stream_chat(
                messages=[ChatMessage(role=MessageRole.USER, content=final_prompt)]
            ):
                if response.content:
                    accumulated_content += response.content
                    sse_response = SSEResponse.create(
                        token=response.content, done=response.is_complete
                    )
                    yield {
                        "node": "make_final_answer",
                        "type": "llm_stream",
                        "sse_response": sse_response,
                        "content": response.content,
                        "is_complete": response.is_complete,
                        "model": response.model_name,
                    }

            # ìµœì¢… ë©”ì‹œì§€ ë°˜í™˜
            yield {"messages": [AIMessage(content=accumulated_content)]}

        except Exception as e:
            logger.error(f"[GRAPH][7/7] ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {e}")
            yield {"node": "make_final_answer", "type": "error", "error": str(e)}
            yield {
                "messages": [
                    AIMessage(content="ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                ]
            }
